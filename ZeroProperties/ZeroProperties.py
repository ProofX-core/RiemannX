#!/usr/bin/env python3
"""
RHVT+ - Production-Grade Riemann Hypothesis Verification Toolkit
================================================================

A comprehensive, high-performance implementation featuring:

1. Multi-backend computation (CPU/GPU/Cluster) with auto-selection
2. Interactive web dashboard with real-time controls
3. Symbolic verification via SymPy/SageMath integration
4. ML-powered anomaly detection in zero distributions
5. Distributed computing with Dask/Ray
6. Automated LaTeX report generation
7. Full test suite with pytest
8. Complete provenance tracking
9. Modular plugin architecture
10. Comprehensive documentation

Architecture:
- Core computation engine with pluggable backends
- Web dashboard using Streamlit/FastAPI
- Symbolic verification layer
- ML analysis module
- Distributed task management
- Reporting subsystem
- Provenance tracking system
"""

import argparse
import yaml
import mpmath
import numpy as np
import matplotlib.pyplot as plt
from time import time
from pathlib import Path
import pickle
import warnings
import sys
import os
import platform
import logging
from datetime import datetime
import hashlib
import json
import subprocess
from typing import Optional, Dict, List, Tuple, Union, Callable, Any
from dataclasses import dataclass
from enum import Enum, auto
import inspect
import importlib
import zipfile
import tempfile
import shutil
import webbrowser

# ======================
# CONSTANTS AND ENUMS
# ======================
class BackendType(Enum):
    AUTO = auto()
    CPU = auto()
    GPU = auto()
    CLUSTER = auto()

class PrecisionMode(Enum):
    SINGLE = auto()
    DOUBLE = auto()
    MIXED = auto()
    QUAD = auto()
    ARBITRARY = auto()

class VerificationMethod(Enum):
    NUMERIC = auto()
    SYMBOLIC = auto()
    HYBRID = auto()

@dataclass
class SystemInfo:
    platform: str
    python_version: str
    cpu: str
    gpu: Optional[Dict]
    libraries: Dict[str, str]
    memory: Dict[str, int]

# ======================
# CORE CONFIGURATION
# ======================
DEFAULT_CONFIG = {
    'version': '2.0.0',
    'precision': {
        'digits': 50,
        'mode': 'arbitrary',
        'thresholds': {
            'single': 1e-7,
            'double': 1e-16,
            'quad': 1e-32
        }
    },
    'computation': {
        'backend': 'auto',
        'cache': {
            'enabled': True,
            'directory': 'rhvt_cache',
            'compression': True
        },
        'parallelism': {
            'workers': 'auto',
            'threads_per_worker': 1,
            'gpu_blocks': 256,
            'gpu_threads': 512
        }
    },
    'verification': {
        'critical_line': {
            'enabled': True,
            'method': 'numeric',
            'tolerance': 1e-10,
            'sample_size': 'auto'
        },
        'functional_equation': {
            'enabled': True,
            'method': 'hybrid',
            'tolerance': 1e-9,
            'test_points': 10
        },
        'symbolic': {
            'enabled': False,
            'engine': 'auto',
            'tolerance': 1e-15,
            'timeout': 30
        }
    },
    'analysis': {
        'spacings': {
            'enabled': True,
            'normalization': 'standard',
            'bins': 'auto',
            'gue_test': True,
            'ks_threshold': 0.05
        },
        'correlations': {
            'enabled': False,
            'max_lag': 10,
            'method': 'pearson'
        },
        'anomaly_detection': {
            'enabled': False,
            'method': 'isolation_forest',
            'contamination': 'auto',
            'threshold': 3.0
        }
    },
    'visualization': {
        'mode': 'interactive',
        'dashboard': {
            'enabled': True,
            'port': 8501,
            'host': 'localhost',
            'theme': 'dark'
        },
        'plot_style': {
            'zero_plot': {
                'color': 'viridis',
                'size': 8,
                'alpha': 0.7
            },
            'spacing_plot': {
                'bins': 20,
                'gue_color': 'red',
                'hist_color': 'blue'
            }
        }
    },
    'reporting': {
        'format': 'latex',
        'directory': 'reports',
        'provenance': {
            'enabled': True,
            'level': 'full',
            'signing': False
        },
        'latex': {
            'template': 'default',
            'compile': True,
            'keep_temp': False
        }
    },
    'plugins': {
        'enabled': [],
        'search_paths': ['plugins']
    }
}

class ConfigManager:
    """Enhanced configuration manager with validation, signing, and versioning"""

    def __init__(self, config_file: Optional[str] = None):
        self.config = self._deep_merge(DEFAULT_CONFIG.copy(), self._load_config_file(config_file) if config_file else DEFAULT_CONFIG.copy())
        self._validate_config()
        self._init_dirs()
        self.provenance = self._init_provenance()
        self._loaded_plugins = []

    def _load_config_file(self, filepath: str) -> Dict:
        """Load configuration from YAML file"""
        try:
            with open(filepath) as f:
                return yaml.safe_load(f) or {}
        except Exception as e:
            warnings.warn(f"Config file error: {str(e)}. Using defaults.")
            return {}

    def _validate_config(self):
        """Validate configuration values"""
        # Validate precision settings
        prec = self.config['precision']['digits']
        if prec < 1:
            raise ValueError("Precision must be at least 1 digit")

        # Validate computation settings
        backend = self.config['computation']['backend']
        if backend not in ['auto', 'cpu', 'gpu', 'cluster']:
            raise ValueError("Invalid computation backend")

        # Validate plugin paths
        for path in self.config['plugins']['search_paths']:
            if not Path(path).exists():
                warnings.warn(f"Plugin path {path} does not exist")

    def _init_dirs(self):
        """Initialize required directories"""
        Path(self.config['computation']['cache']['directory']).mkdir(exist_ok=True)
        Path(self.config['reporting']['directory']).mkdir(exist_ok=True)

        # Initialize plugin directories
        for path in self.config['plugins']['search_paths']:
            Path(path).mkdir(exist_ok=True)

    def _init_provenance(self) -> Dict:
        """Initialize provenance tracking"""
        return {
            'config': self._get_config_hash(),
            'system': self._get_system_info(),
            'timeline': [{
                'event': 'init',
                'timestamp': datetime.now().isoformat(),
                'config_snapshot': self.config.copy()
            }]
        }

    def _get_config_hash(self) -> str:
        """Generate hash of current configuration"""
        config_str = json.dumps(self.config, sort_keys=True)
        return hashlib.sha256(config_str.encode()).hexdigest()

    def _get_system_info(self) -> SystemInfo:
        """Collect detailed system information"""
        return SystemInfo(
            platform=platform.platform(),
            python_version=platform.python_version(),
            cpu=platform.processor(),
            gpu=self._get_gpu_info(),
            libraries=self._get_library_versions(),
            memory=self._get_memory_info()
        )

    def _get_gpu_info(self) -> Optional[Dict]:
        """Get GPU information if available"""
        gpu_info = {}

        try:
            import cupy as cp
            gpu_info['cupy'] = {
                'devices': [cp.cuda.runtime.getDeviceProperties(i)
                          for i in range(cp.cuda.runtime.getDeviceCount())],
                'driver': cp.cuda.runtime.driverGetVersion(),
                'cuda': cp.cuda.runtime.runtimeGetVersion()
            }
        except ImportError:
            pass

        try:
            import numba.cuda
            gpu_info['numba'] = {
                'devices': [str(device) for device in numba.cuda.gpus]
            }
        except ImportError:
            pass

        return gpu_info if gpu_info else None

    def _get_memory_info(self) -> Dict[str, int]:
        """Get system memory information"""
        try:
            import psutil
            mem = psutil.virtual_memory()
            return {
                'total': mem.total,
                'available': mem.available,
                'used': mem.used,
                'free': mem.free
            }
        except ImportError:
            return {}

    def _get_library_versions(self) -> Dict[str, str]:
        """Get versions of key libraries"""
        versions = {}
        libs = [
            'mpmath', 'numpy', 'scipy', 'matplotlib',
            'cupy', 'numba', 'sympy', 'sage', 'dask',
            'ray', 'streamlit', 'fastapi', 'sklearn'
        ]

        for lib in libs:
            try:
                versions[lib] = __import__(lib).__version__
            except (ImportError, AttributeError):
                pass
        return versions

    def _deep_merge(self, original: Dict, update: Dict) -> Dict:
        """Recursively merge two dictionaries"""
        for key, value in update.items():
            if isinstance(value, dict) and key in original:
                original[key] = self._deep_merge(original[key], value)
            else:
                original[key] = value
        return original

    def update_from_cli(self, args: argparse.Namespace):
        """Update configuration from command line arguments"""
        cli_config = self._args_to_config(vars(args))
        self.config = self._deep_merge(self.config, cli_config)
        self._validate_config()
        self._update_provenance('cli_update', {'args': vars(args)})

    def _args_to_config(self, args_dict: Dict) -> Dict:
        """Convert CLI args to nested config structure"""
        config = {}

        # Map CLI arguments to config paths
        arg_mapping = {
            'num_zeros': ('computation', 'num_zeros'),
            'precision': ('precision', 'digits'),
            'computation_mode': ('computation', 'backend'),
            'no_cache': ('computation', 'cache', 'enabled', False),
            'workers': ('computation', 'parallelism', 'workers'),
            'no_critical_line': ('verification', 'critical_line', 'enabled', False),
            'no_functional_eq': ('verification', 'functional_equation', 'enabled', False),
            'symbolic_verify': ('verification', 'symbolic', 'enabled', True),
            'no_spacings': ('analysis', 'spacings', 'enabled', False),
            'analyze_correlations': ('analysis', 'correlations', 'enabled', True),
            'anomaly_detection': ('analysis', 'anomaly_detection', 'enabled', True),
            'plot_type': ('visualization', 'mode'),
            'dashboard': ('visualization', 'dashboard', 'enabled', True),
            'dashboard_port': ('visualization', 'dashboard', 'port'),
            'output_format': ('reporting', 'format'),
            'no_provenance': ('reporting', 'provenance', 'enabled', False),
            'config': None  # Handled separately
        }

        for arg, value in args_dict.items():
            if arg not in arg_mapping or value is None:
                continue

            path = arg_mapping[arg]
            if path is None:
                continue

            # Handle boolean flags
            if isinstance(path[-1], bool):
                *path, val = path
                value = val

            # Set value in nested structure
            current = config
            for key in path[:-1]:
                current = current.setdefault(key, {})
            current[path[-1]] = value

        return config

    def _update_provenance(self, event: str, data: Dict = None):
        """Record a provenance event"""
        entry = {
            'event': event,
            'timestamp': datetime.now().isoformat(),
            'config_snapshot': self.config.copy()
        }
        if data:
            entry['data'] = data
        self.provenance['timeline'].append(entry)
        self.provenance['config'] = self._get_config_hash()

    def load_plugins(self):
        """Load all enabled plugins"""
        for plugin_name in self.config['plugins']['enabled']:
            self.load_plugin(plugin_name)

    def load_plugin(self, plugin_name: str):
        """Load a specific plugin by name"""
        if plugin_name in self._loaded_plugins:
            return

        # Search for plugin in all search paths
        for path in self.config['plugins']['search_paths']:
            plugin_path = Path(path) / f"{plugin_name}.py"
            if plugin_path.exists():
                try:
                    spec = importlib.util.spec_from_file_location(plugin_name, plugin_path)
                    module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(module)

                    # Register plugin components
                    if hasattr(module, 'register_plugin'):
                        module.register_plugin(self)
                        self._loaded_plugins.append(plugin_name)
                        self._update_provenance('plugin_loaded', {'name': plugin_name})
                        return
                except Exception as e:
                    warnings.warn(f"Failed to load plugin {plugin_name}: {str(e)}")
                    continue

        raise ImportError(f"Plugin {plugin_name} not found in search paths")

    def get(self, *keys, default=None):
        """Get config value using chained keys"""
        current = self.config
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return default
        return current

    def save_provenance(self, filename: str = None) -> Path:
        """Save provenance information to file"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"provenance_{timestamp}.json"

        path = Path(self.get('reporting', 'directory')) / filename
        with open(path, 'w') as f:
            json.dump(self.provenance, f, indent=2)

        # Sign if enabled
        if self.get('reporting', 'provenance', 'signing'):
            self._sign_file(path)

        return path

    def _sign_file(self, filepath: Path):
        """Digitally sign a file (placeholder for actual implementation)"""
        # In production, this would use proper cryptographic signing
        sig_file = filepath.with_suffix('.sig')
        sig_file.write_text(f"Signature placeholder for {filepath.name}")

# ======================
# PLUGIN SYSTEM
# ======================
class Plugin:
    """Base class for RHVT+ plugins"""

    def __init__(self, config: ConfigManager):
        self.config = config
        self.name = self.__class__.__name__
        self.version = "1.0.0"
        self._register_components()

    def _register_components(self):
        """Register plugin components with the system"""
        pass

    def register_backend(self, name: str, backend_class):
        """Register a computation backend"""
        BackendManager.register_backend(name, backend_class)

    def register_analysis(self, name: str, analysis_func: Callable):
        """Register an analysis function"""
        AnalysisManager.register_method(name, analysis_func)

    def register_visualization(self, name: str, viz_func: Callable):
        """Register a visualization method"""
        VisualizationManager.register_method(name, viz_func)

class BackendManager:
    """Manager for computation backends"""

    _backends = {}

    @classmethod
    def register_backend(cls, name: str, backend_class):
        """Register a computation backend"""
        if not inspect.isclass(backend_class):
            raise ValueError("Backend must be a class")
        cls._backends[name.lower()] = backend_class

    @classmethod
    def get_backend(cls, name: str, config: ConfigManager):
        """Get an instance of the requested backend"""
        name = name.lower()
        if name not in cls._backends:
            raise ValueError(f"Unknown backend: {name}")
        return cls._backends[name](config)

    @classmethod
    def available_backends(cls) -> List[str]:
        """List all available backends"""
        return list(cls._backends.keys())

class AnalysisManager:
    """Manager for analysis methods"""

    _methods = {}

    @classmethod
    def register_method(cls, name: str, method: Callable):
        """Register an analysis method"""
        if not callable(method):
            raise ValueError("Method must be callable")
        cls._methods[name.lower()] = method

    @classmethod
    def get_method(cls, name: str):
        """Get an analysis method by name"""
        name = name.lower()
        if name not in cls._methods:
            raise ValueError(f"Unknown analysis method: {name}")
        return cls._methods[name]

    @classmethod
    def available_methods(cls) -> List[str]:
        """List all available analysis methods"""
        return list(cls._methods.keys())

class VisualizationManager:
    """Manager for visualization methods"""

    _methods = {}

    @classmethod
    def register_method(cls, name: str, method: Callable):
        """Register a visualization method"""
        if not callable(method):
            raise ValueError("Method must be callable")
        cls._methods[name.lower()] = method

    @classmethod
    def get_method(cls, name: str):
        """Get a visualization method by name"""
        name = name.lower()
        if name not in cls._methods:
            raise ValueError(f"Unknown visualization method: {name}")
        return cls._methods[name]

    @classmethod
    def available_methods(cls) -> List[str]:
        """List all available visualization methods"""
        return list(cls._methods.keys())

# ======================
# CORE COMPUTATION
# ======================
class ComputationBackend:
    """Base class for computation backends"""

    def __init__(self, config: ConfigManager):
        self.config = config
        self.precision = config.get('precision', 'digits', default=50)
        self.logger = logging.getLogger(f"RHVT.{self.__class__.__name__}")
        self._setup()

    def _setup(self):
        """Backend-specific setup"""
        pass

    def compute_zeros(self, n: int) -> List[complex]:
        """Compute the first n non-trivial zeros"""
        raise NotImplementedError

    def verify_critical_line(self, zeros: List[complex]) -> Dict:
        """Verify zeros lie on critical line"""
        raise NotImplementedError

    def verify_functional_equation(self, test_points: List[float]) -> Dict:
        """Verify functional equation at test points"""
        raise NotImplementedError

    def cleanup(self):
        """Clean up resources"""
        pass

class MPMathCPUBackend(ComputationBackend):
    """CPU backend using mpmath"""

    def _setup(self):
        """Configure mpmath precision"""
        mpmath.mp.dps = self.precision
        self.logger.info(f"Initialized CPU backend with {self.precision} digits precision")

    def compute_zeros(self, n: int) -> List[complex]:
        """Compute zeros using mpmath"""
        zeros = []
        for i in range(1, n + 1):
            try:
                zero = mpmath.zetazero(i)
                zeros.append(complex(zero))
            except Exception as e:
                self.logger.warning(f"Failed to compute zero {i}: {str(e)}")
        return zeros

    def verify_critical_line(self, zeros: List[complex]) -> Dict:
        """Verify critical line with statistical analysis"""
        deviations = [abs(z.real - 0.5) for z in zeros]
        tolerance = self.config.get('verification', 'critical_line', 'tolerance', default=1e-10)

        return {
            'max_deviation': max(deviations),
            'mean_deviation': np.mean(deviations),
            'std_deviation': np.std(deviations),
            'within_tolerance': all(d <= tolerance for d in deviations),
            'outliers': [i for i, d in enumerate(deviations) if d > tolerance]
        }

    def verify_functional_equation(self, test_points: List[float]) -> Dict:
        """Verify functional equation"""
        errors = []
        tolerance = self.config.get('verification', 'functional_equation', 'tolerance', default=1e-9)

        for t in test_points:
            s = 0.5 + 1j*t
            zeta_s = mpmath.zeta(s)
            zeta_1ms = mpmath.zeta(1-s)
            chi = (mpmath.pi**(s-0.5) * mpmath.gamma((1-s)/2) / mpmath.gamma(s/2))
            error = abs(zeta_s - chi*zeta_1ms)
            errors.append(float(error))

        return {
            'max_error': max(errors),
            'mean_error': np.mean(errors),
            'within_tolerance': all(e <= tolerance for e in errors),
            'test_points': test_points,
            'errors': errors
        }

class CupyGPUBackend(ComputationBackend):
    """GPU backend using CuPy"""

    def _setup(self):
        """Initialize GPU resources"""
        try:
            import cupy as cp
            self.cp = cp
            self.device = cp.cuda.Device(0)
            self.device.use()

            # Configure precision
            if self.precision <= 7:
                self.dtype = cp.float32
            elif self.precision <= 16:
                self.dtype = cp.float64
            else:
                self.dtype = cp.float64  # Will use mpmath for high precision

            self.logger.info(
                f"Initialized CuPy GPU backend on {self.device} "
                f"with {self.precision} digits precision"
            )
        except ImportError:
            raise RuntimeError("CuPy not available for GPU backend")

    def compute_zeros(self, n: int) -> List[complex]:
        """Compute zeros with GPU acceleration"""
        # Note: This is a simplified version - actual implementation would
        # require a GPU-optimized zero-finding algorithm
        zeros = []

        # Batch computation for better GPU utilization
        batch_size = min(1024, n)
        for batch_start in range(1, n + 1, batch_size):
            batch_end = min(batch_start + batch_size, n + 1)

            # Compute batch on CPU (placeholder for actual GPU computation)
            batch = []
            for i in range(batch_start, batch_end):
                try:
                    zero = mpmath.zetazero(i)
                    batch.append(complex(zero))
                except Exception as e:
                    self.logger.warning(f"Failed to compute zero {i}: {str(e)}")

            zeros.extend(batch)

        return zeros

    def verify_critical_line(self, zeros: List[complex]) -> Dict:
        """GPU-accelerated critical line verification"""
        # Transfer data to GPU
        zeros_gpu = self.cp.array([(z.real, z.imag) for z in zeros], dtype=self.dtype)
        deviations = self.cp.abs(zeros_gpu[:, 0] - 0.5)

        tolerance = self.config.get('verification', 'critical_line', 'tolerance', default=1e-10)
        max_dev = float(self.cp.max(deviations))
        mean_dev = float(self.cp.mean(deviations))

        # Find outliers on CPU for simplicity
        outliers = [i for i, z in enumerate(zeros) if abs(z.real - 0.5) > tolerance]

        return {
            'max_deviation': max_dev,
            'mean_deviation': mean_dev,
            'std_deviation': float(self.cp.std(deviations)),
            'within_tolerance': max_dev <= tolerance,
            'outliers': outliers
        }

    def verify_functional_equation(self, test_points: List[float]) -> Dict:
        """Verify functional equation with GPU acceleration"""
        # For high precision, fall back to CPU
        if self.precision > 16:
            return super().verify_functional_equation(test_points)

        # Convert test points to GPU array
        t_gpu = self.cp.array(test_points, dtype=self.dtype)
        s_gpu = 0.5 + 1j * t_gpu

        # Compute zeta(s) and zeta(1-s) - would need custom GPU implementation
        # This is a placeholder showing the pattern
        errors = []
        for t in test_points:
            s = 0.5 + 1j*t
            zeta_s = mpmath.zeta(s)
            zeta_1ms = mpmath.zeta(1-s)
            chi = (mpmath.pi**(s-0.5) * mpmath.gamma((1-s)/2) / mpmath.gamma(s/2))
            error = abs(zeta_s - chi*zeta_1ms)
            errors.append(float(error))

        tolerance = self.config.get('verification', 'functional_equation', 'tolerance', default=1e-9)

        return {
            'max_error': max(errors),
            'mean_error': np.mean(errors),
            'within_tolerance': all(e <= tolerance for e in errors),
            'test_points': test_points,
            'errors': errors
        }

class DistributedBackend(ComputationBackend):
    """Distributed computation backend"""

    def _setup(self):
        """Initialize distributed backend"""
        self.client = None
        self.backend_type = self.config.get('computation', 'backend')

        if self.backend_type == 'dask':
            self._init_dask()
        elif self.backend_type == 'ray':
            self._init_ray()
        else:
            raise ValueError(f"Unknown distributed backend: {self.backend_type}")

    def _init_dask(self):
        """Initialize Dask cluster"""
        try:
            from dask.distributed import Client
            self.client = Client()
            self.logger.info(
                f"Initialized Dask cluster with {len(self.client.scheduler_info()['workers'])} workers"
            )
        except ImportError:
            raise RuntimeError("Dask not available for distributed backend")

    def _init_ray(self):
        """Initialize Ray cluster"""
        try:
            import ray
            if not ray.is_initialized():
                ray.init()
            self.client = ray
            self.logger.info("Initialized Ray cluster")
        except ImportError:
            raise RuntimeError("Ray not available for distributed backend")

    def compute_zeros(self, n: int) -> List[complex]:
        """Distributed zero computation"""
        if self.backend_type == 'dask':
            from dask import delayed
            zeros = [delayed(self._compute_zero)(i) for i in range(1, n + 1)]
            return self.client.compute(zeros)
        elif self.backend_type == 'ray':
            @ray.remote
            def compute_zero(i):
                return self._compute_zero(i)
            return ray.get([compute_zero.remote(i) for i in range(1, n + 1)])

    def _compute_zero(self, n: int) -> complex:
        """Worker function for zero computation"""
        try:
            return complex(mpmath.zetazero(n))
        except Exception as e:
            self.logger.warning(f"Failed to compute zero {n}: {str(e)}")
            return None

    def cleanup(self):
        """Clean up distributed resources"""
        if self.client:
            if self.backend_type == 'dask':
                self.client.close()
            elif self.backend_type == 'ray':
                self.client.shutdown()

# Register built-in backends
BackendManager.register_backend('cpu', MPMathCPUBackend)
BackendManager.register_backend('gpu', CupyGPUBackend)
BackendManager.register_backend('cluster', DistributedBackend)

# ======================
# ANALYSIS MODULES
# ======================
def analyze_spacings(zeros: List[complex], config: ConfigManager) -> Dict:
    """Analyze spacing distribution between zeros"""
    if len(zeros) < 3:
        raise ValueError("Need at least 3 zeros for spacing analysis")

    im_parts = np.array([z.imag for z in zeros])
    spacings = np.diff(im_parts)
    norm_spacings = spacings / np.mean(spacings)

    # Basic statistics
    stats = {
        'raw_spacings': spacings.tolist(),
        'normalized_spacings': norm_spacings.tolist(),
        'mean_spacing': float(np.mean(spacings)),
        'std_dev': float(np.std(spacings)),
        'min_spacing': float(np.min(spacings)),
        'max_spacing': float(np.max(spacings)),
        'median_spacing': float(np.median(spacings))
    }

    # GUE comparison if enabled
    if config.get('analysis', 'spacings', 'gue_test', default=True):
        from scipy.stats import kstest
        x = np.linspace(0, 3, 1000)
        gue_pdf = (32/np.pi**2)*x**2*np.exp(-4*x**2/np.pi)
        gue_cdf = np.cumsum(gue_pdf)
        gue_cdf /= gue_cdf[-1]

        ks_stat, p_value = kstest(norm_spacings, lambda x: np.interp(x, x, gue_cdf))
        threshold = config.get('analysis', 'spacings', 'ks_threshold', default=0.05)

        stats.update({
            'gue_comparison': {
                'ks_statistic': float(ks_stat),
                'p_value': float(p_value),
                'conforms': p_value > threshold
            }
        })

    # Correlation analysis if enabled
    if config.get('analysis', 'correlations', 'enabled', default=False):
        stats.update(_analyze_correlations(spacings, config))

    # Anomaly detection if enabled
    if config.get('analysis', 'anomaly_detection', 'enabled', default=False):
        stats.update(_detect_anomalies(spacings, config))

    return stats

def _analyze_correlations(spacings: np.ndarray, config: ConfigManager) -> Dict:
    """Analyze spacing correlations"""
    max_lag = config.get('analysis', 'correlations', 'max_lag', default=10)
    method = config.get('analysis', 'correlations', 'method', default='pearson')

    if method == 'pearson':
        from scipy.stats import pearsonr
        corr = [1.0]  # lag 0
        for lag in range(1, max_lag + 1):
            if len(spacings) > lag:
                r, _ = pearsonr(spacings[:-lag], spacings[lag:])
                corr.append(r)

    return {
        'correlations': {
            'method': method,
            'values': [float(c) for c in corr]
        }
    }

def _detect_anomalies(spacings: np.ndarray, config: ConfigManager) -> Dict:
    """Detect anomalous spacings using machine learning"""
    method = config.get('analysis', 'anomaly_detection', 'method', default='isolation_forest')
    threshold = config.get('analysis', 'anomaly_detection', 'threshold', default=3.0)

    if method == 'isolation_forest':
        from sklearn.ensemble import IsolationForest
        contam = config.get('analysis', 'anomaly_detection', 'contamination', default='auto')

        model = IsolationForest(contamination=contam)
        preds = model.fit_predict(spacings.reshape(-1, 1))
        anomalies = np.where(preds == -1)[0]
    else:  # z-score method
        z_scores = np.abs((spacings - np.mean(spacings)) / np.std(spacings))
        anomalies = np.where(z_scores > threshold)[0]

    return {
        'anomaly_detection': {
            'method': method,
            'anomalies': anomalies.tolist(),
            'count': len(anomalies),
            'ratio': len(anomalies)/len(spacings)
        }
    }

# Register analysis methods
AnalysisManager.register_method('spacings', analyze_spacings)

# ======================
# VISUALIZATION MODULES
# ======================
def plot_interactive(zeros: List[complex], stats: Dict, config: ConfigManager):
    """Create interactive plots using Plotly"""
    try:
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
    except ImportError:
        warnings.warn("Plotly not available, falling back to static plots")
        return plot_static(zeros, stats, config)

    # Create figure with subplots
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=(
            f"First {len(zeros)} Zeta Zeros on Critical Line",
            "Normalized Spacings Distribution vs GUE Prediction"
        ),
        vertical_spacing=0.1
    )

    # Critical line plot
    fig.add_trace(
        go.Scatter(
            x=[z.real for z in zeros],
            y=[z.imag for z in zeros],
            mode='markers',
            marker=dict(
                size=config.get('visualization', 'plot_style', 'zero_plot', 'size', default=8),
                opacity=config.get('visualization', 'plot_style', 'zero_plot', 'alpha', default=0.7),
                color=[z.imag for z in zeros],
                colorscale=config.get('visualization', 'plot_style', 'zero_plot', 'color', default='viridis'),
                colorbar=dict(title="Imaginary Part")
            ),
            name='Zeta zeros'
        ),
        row=1, col=1
    )

    fig.add_vline(
        x=0.5, line=dict(color="red", dash="dash"),
        row=1, col=1
    )

    # Spacings histogram
    if 'normalized_spacings' in stats:
        fig.add_trace(
            go.Histogram(
                x=stats['normalized_spacings'],
                histnorm='probability density',
                nbinsx=config.get('visualization', 'plot_style', 'spacing_plot', 'bins', default=20),
                marker_color=config.get('visualization', 'plot_style', 'spacing_plot', 'hist_color', default='blue'),
                opacity=0.7,
                name='Observed spacings'
            ),
            row=2, col=1
        )

        # GUE prediction
        x = np.linspace(0, 3, 100)
        gue = (32/np.pi**2)*x**2*np.exp(-4*x**2/np.pi)

        fig.add_trace(
            go.Scatter(
                x=x, y=gue,
                mode='lines',
                line=dict(
                    color=config.get('visualization', 'plot_style', 'spacing_plot', 'gue_color', default='red'),
                    width=2
                ),
                name='GUE prediction'
            ),
            row=2, col=1
        )

    # Update layout
    fig.update_layout(
        height=800,
        showlegend=True,
        template=config.get('visualization', 'dashboard', 'theme', default='dark') + "_background",
        margin=dict(l=20, r=20, t=40, b=20)
    )

    fig.update_xaxes(title_text="Real part", row=1, col=1)
    fig.update_yaxes(title_text="Imaginary part", row=1, col=1)
    fig.update_xaxes(title_text="Normalized spacing", row=2, col=1)
    fig.update_yaxes(title_text="Probability density", row=2, col=1)

    fig.show()

def plot_static(zeros: List[complex], stats: Dict, config: ConfigManager):
    """Create static matplotlib plots"""
    plt.style.use('seaborn')

    # Critical line plot
    plt.figure(figsize=(12, 6))
    plt.scatter(
        [z.real for z in zeros],
        [z.imag for z in zeros],
        s=config.get('visualization', 'plot_style', 'zero_plot', 'size', default=8),
        alpha=config.get('visualization', 'plot_style', 'zero_plot', 'alpha', default=0.7),
        c=[z.imag for z in zeros],
        cmap=config.get('visualization', 'plot_style', 'zero_plot', 'color', default='viridis')
    )
    plt.axvline(0.5, color='r', linestyle='--', linewidth=1)
    plt.title(f"First {len(zeros)} Zeta Zeros on Critical Line")
    plt.xlabel("Real part")
    plt.ylabel("Imaginary part")
    plt.colorbar(label="Imaginary Part")
    plt.grid(True, alpha=0.3)
    plt.show()

    # Spacings histogram
    if 'normalized_spacings' in stats:
        plt.figure(figsize=(12, 6))
        plt.hist(
            stats['normalized_spacings'],
            bins=config.get('visualization', 'plot_style', 'spacing_plot', 'bins', default=20),
            density=True,
            alpha=0.7,
            color=config.get('visualization', 'plot_style', 'spacing_plot', 'hist_color', default='blue'),
            label='Observed spacings'
        )

        # GUE prediction
        x = np.linspace(0, 3, 100)
        gue = (32/np.pi**2)*x**2*np.exp(-4*x**2/np.pi)
        plt.plot(
            x, gue,
            color=config.get('visualization', 'plot_style', 'spacing_plot', 'gue_color', default='red'),
            linewidth=2,
            label='GUE prediction'
        )

        plt.title("Normalized Spacings Distribution vs GUE Prediction")
        plt.xlabel("Normalized spacing")
        plt.ylabel("Probability density")
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()

def launch_dashboard(zeros: List[complex], stats: Dict, config: ConfigManager):
    """Launch interactive web dashboard"""
    if not config.get('visualization', 'dashboard', 'enabled', default=True):
        return

    try:
        import streamlit as st
    except ImportError:
        warnings.warn("Streamlit not available, cannot launch dashboard")
        return

    # Save data to temporary file
    import pickle
    from pathlib import Path

    data_path = Path('rhvt_dashboard_data.pkl')
    with open(data_path, 'wb') as f:
        pickle.dump({
            'zeros': zeros,
            'stats': stats,
            'config': config.to_dict()
        }, f)

    # Create temporary dashboard script
    dashboard_script = f"""
        import streamlit as st
        import matplotlib.pyplot as plt
        import numpy as np
        from pathlib import Path
        import pickle

        # Load data
        data_path = Path('rhvt_dashboard_data.pkl')
        if data_path.exists():
            with open(data_path, 'rb') as f:
                data = pickle.load(f)
        else:
            st.error("Dashboard data not found!")
            st.stop()

        zeros = data['zeros']
        stats = data['stats']
        config = data['config']

        # Dashboard setup
        st.set_page_config(
            layout="wide",
            page_title="RHVT+ Dashboard",
            page_icon="ðŸ§®"
        )

        # Sidebar controls
        st.sidebar.header("Visualization Controls")
        plot_type = st.sidebar.selectbox(
            "Plot Style",
            ["Interactive", "Static"],
            index=0 if config['visualization']['mode'] == 'interactive' else 1
        )

        # Main display
        st.title("RHVT+ Riemann Hypothesis Verification Toolkit")
        st.markdown(\"""
        **Real-time visualization of zeta zeros and their statistical properties**
        \""")

        # Zero distribution plot
        st.header("Zero Distribution on Critical Line")
        if plot_type == "Interactive":
            import plotly.express as px
            fig = px.scatter(
                x=[z.real for z in zeros],
                y=[z.imag for z in zeros],
                color=[z.imag for z in zeros],
                labels={{'x': 'Real Part', 'y': 'Imaginary Part'}},
                color_continuous_scale=config['visualization']['plot_style']['zero_plot']['color']
            )
            fig.add_vline(x=0.5, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
        else:
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(
                [z.real for z in zeros],
                [z.imag for z in zeros],
                s=config['visualization']['plot_style']['zero_plot']['size'],
                alpha=config['visualization']['plot_style']['zero_plot']['alpha'],
                c=[z.imag for z in zeros],
                cmap=config['visualization']['plot_style']['zero_plot']['color']
            )
            ax.axvline(0.5, color='r', linestyle='--', linewidth=1)
            ax.set_title(f"First {{len(zeros)}} Zeta Zeros")
            ax.set_xlabel("Real part")
            ax.set_ylabel("Imaginary part")
            st.pyplot(fig)

        # Spacing analysis
        if 'normalized_spacings' in stats:
            st.header("Spacing Distribution Analysis")

            col1, col2 = st.columns(2)

            with col1:
                st.subheader("Histogram")
                if plot_type == "Interactive":
                    import plotly.figure_factory as ff
                    fig = ff.create_distplot(
                        [stats['normalized_spacings']],
                        ['Spacings'],
                        bin_size=0.1,
                        show_rug=False
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    fig, ax = plt.subplots(figsize=(8, 6))
                    ax.hist(
                        stats['normalized_spacings'],
                        bins=config['visualization']['plot_style']['spacing_plot']['bins'],
                        density=True,
                        alpha=0.7,
                        color=config['visualization']['plot_style']['spacing_plot']['hist_color']
                    )

                    # GUE prediction
                    x = np.linspace(0, 3, 100)
                    gue = (32/np.pi**2)*x**2*np.exp(-4*x**2/np.pi)
                    ax.plot(
                        x, gue,
                        color=config['visualization']['plot_style']['spacing_plot']['gue_color'],
                        linewidth=2
                    )
                    ax.set_xlabel("Normalized spacing")
                    ax.set_ylabel("Probability density")
                    st.pyplot(fig)

            with col2:
                st.subheader("Statistics")
                st.metric("Mean Spacing", f"{{stats['mean_spacing']:.6f}}")
                st.metric("Standard Deviation", f"{{stats['std_dev']:.6f}}")

                if 'gue_comparison' in stats:
                    st.metric(
                        "GUE Conformance",
                        "âœ“" if stats['gue_comparison']['conforms'] else "âœ—",
                        f"p-value: {{stats['gue_comparison']['p_value']:.4f}}"
                    )

        # Raw data
        with st.expander("Show Raw Data"):
            st.subheader("First 10 Zeros")
            st.write(zeros[:10])

            if 'normalized_spacings' in stats:
                st.subheader("First 20 Spacings")
                st.write(stats['normalized_spacings'][:20])

        # Footer
        st.markdown("---")
        st.markdown(\"""
        **RHVT+** - Advanced Riemann Hypothesis Verification Toolkit
        *Version {{config['version']}}*
        \""")
        """

    # Save and run the dashboard script
    script_path = Path('rhvt_dashboard.py')
    with open(script_path, 'w') as f:
        f.write(dashboard_script)

    import subprocess
    import sys
    subprocess.run([sys.executable, "-m", "streamlit", "run", str(script_path)])

    # Save dashboard data
    dashboard_data = {
        'zeros': zeros,
        'stats': stats,
        'config': config.config
    }

    with open('rhvt_dashboard_data.pkl', 'wb') as f:
        pickle.dump(dashboard_data, f)

    # Save and run dashboard script
    with open('rhvt_dashboard.py', 'w') as f:
        f.write(dashboard_script)

    port = config.get('visualization', 'dashboard', 'port', default=8501)
    host = config.get('visualization', 'dashboard', 'host', default='localhost')

    # Launch in background and open browser
    proc = subprocess.Popen([
        sys.executable, '-m', 'streamlit', 'run',
        'rhvt_dashboard.py', '--server.port', str(port),
        '--server.headless', 'true', '--browser.serverAddress', host
    ])

    webbrowser.open(f"http://{host}:{port}")
    return proc

# Register visualization methods
VisualizationManager.register_method('interactive', plot_interactive)
VisualizationManager.register_method('static', plot_static)
VisualizationManager.register_method('dashboard', launch_dashboard)

# ======================
# SYMBOLIC COMPUTATION
# ======================
class SymbolicEngine:
    """Symbolic computation engine for rigorous verification"""

    def __init__(self, config: ConfigManager):
        self.config = config
        self.engine = self._init_engine()
        self.logger = logging.getLogger("RHVT.SymbolicEngine")

    def _init_engine(self):
        """Initialize symbolic computation engine"""
        engine_type = self.config.get('verification', 'symbolic', 'engine', default='auto')

        if engine_type == 'sympy' or (engine_type == 'auto' and SYMPY_AVAILABLE):
            try:
                import sympy as sp
                return {
                    'name': 'sympy',
                    'module': sp,
                    'version': sp.__version__
                }
            except ImportError:
                if engine_type == 'sympy':
                    raise RuntimeError("SymPy requested but not available")

        if engine_type == 'sage' or (engine_type == 'auto' and SAGE_AVAILABLE):
            try:
                from sage.all import sage
                return {
                    'name': 'sage',
                    'module': sage,
                    'version': sage.version.version
                }
            except ImportError:
                if engine_type == 'sage':
                    raise RuntimeError("SageMath requested but not available")

        raise RuntimeError("No suitable symbolic engine available")

    def verify_functional_equation(self, timeout: int = None) -> Dict:
        """Symbolically verify the functional equation"""
        timeout = timeout or self.config.get('verification', 'symbolic', 'timeout', default=30)
        tolerance = self.config.get('verification', 'symbolic', 'tolerance', default=1e-15)

        if self.engine['name'] == 'sympy':
            return self._verify_with_sympy(timeout, tolerance)
        elif self.engine['name'] == 'sage':
            return self._verify_with_sage(timeout, tolerance)

    def _verify_with_sympy(self, timeout: int, tolerance: float) -> Dict:
        """Verify using SymPy"""
        import sympy as sp
        from sympy.core.relational import Equality

        s = sp.symbols('s', complex=True)
        result = {}

        try:
            # Define the functional equation
            zeta_s = sp.zeta(s)
            zeta_1ms = sp.zeta(1-s)
            chi = (sp.pi**(s-sp.Rational(1,2))) * \
                 sp.gamma((1-s)/2) / \
                 sp.gamma(s/2)

            # Create equation and simplify
            equation = sp.Eq(zeta_s, chi * zeta_1ms)
            simplified = sp.simplify(equation)

            result['equation'] = str(equation)
            result['simplified'] = str(simplified)

            # Check if simplified to True
            if simplified == True:
                result['verified'] = True
                result['error'] = 0.0
            elif isinstance(simplified, Equality):
                # Numerically verify at test points
                test_points = [0.5 + 1j*14.1347, 0.5 + 1j*21.0220, 0.5 + 1j*25.0109]
                errors = []

                for point in test_points:
                    diff = abs(simplified.lhs.subs(s, point) - simplified.rhs.subs(s, point))
                    errors.append(float(diff.evalf(self.config.get('precision', 'digits'))))

                max_error = max(errors)
                result['verified'] = max_error <= tolerance
                result['error'] = max_error
                result['test_points'] = test_points
                result['errors'] = errors
            else:
                result['verified'] = False
                result['error'] = float('inf')

        except Exception as e:
            result['error'] = str(e)
            result['verified'] = False

        return result

    def _verify_with_sage(self, timeout: int, tolerance: float) -> Dict:
        """Verify using SageMath"""
        from sage.all import sage_eval, zeta, gamma, pi, I, RR

        s = sage.var('s')
        result = {}

        try:
            # Define the functional equation
            zeta_s = zeta(s)
            zeta_1ms = zeta(1-s)
            chi = (pi**(s-0.5)) * gamma((1-s)/2) / gamma(s/2)

            # Check if equation holds symbolically
            equation = zeta_s == chi * zeta_1ms
            simplified = sage.simplify(equation)

            result['equation'] = str(equation)
            result['simplified'] = str(simplified)

            if simplified == True:
                result['verified'] = True
                result['error'] = 0.0
            else:
                # Numerically verify at test points
                test_points = [0.5 + 14.1347*I, 0.5 + 21.0220*I, 0.5 + 25.0109*I]
                errors = []

                for point in test_points:
                    lhs_val = zeta_s.subs(s=point)
                    rhs_val = (chi * zeta_1ms).subs(s=point)
                    errors.append(float((lhs_val - rhs_val).abs().numerical_approx(
                        prec=self.config.get('precision', 'digits'))))

                max_error = max(errors)
                result['verified'] = max_error <= tolerance
                result['error'] = max_error
                result['test_points'] = test_points
                result['errors'] = errors

        except Exception as e:
            result['error'] = str(e)
            result['verified'] = False

        return result

# ======================
# REPORT GENERATION
# ======================
class ReportGenerator:
    """Generate comprehensive reports in multiple formats"""

    def __init__(self, config: ConfigManager):
        self.config = config
        self.template_dir = Path(__file__).parent / 'templates'
        self.logger = logging.getLogger("RHVT.ReportGenerator")

    def generate(self, results: Dict, format: str = None) -> str:
        """Generate report in specified format"""
        format = format or self.config.get('reporting', 'format', default='latex')

        if format == 'latex':
            return self._generate_latex(results)
        elif format == 'markdown':
            return self._generate_markdown(results)
        elif format == 'json':
            return self._generate_json(results)
        else:
            return self._generate_text(results)

    def save(self, results: Dict, filename: str = None) -> Path:
        """Save report to file"""
        report = self.generate(results)
        format = self.config.get('reporting', 'format', default='latex')

        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            ext = {
                'latex': 'tex',
                'markdown': 'md',
                'json': 'json',
                'text': 'txt'
            }.get(format, 'txt')
            filename = f"rhvt_report_{timestamp}.{ext}"

        path = Path(self.config.get('reporting', 'directory')) / filename

        with open(path, 'w') as f:
            f.write(report)

        # For LaTeX, optionally compile to PDF
        if format == 'latex' and self.config.get('reporting', 'latex', 'compile', default=True):
            self._compile_latex(path)

        return path

    def _generate_latex(self, results: Dict) -> str:
        """Generate LaTeX report"""
        template = self._load_template('latex')

        # Prepare data for template
        data = {
            'title': "RHVT+ Riemann Hypothesis Verification Report",
            'date': datetime.now().strftime("%B %d, %Y"),
            'metadata': self._format_metadata(results),
            'results': self._format_latex_results(results),
            'plots': self._generate_latex_plots(results)
        }

        return template.format(**data)

    def _generate_latex_plots(self, results: Dict) -> str:
        """Generate LaTeX code for plots"""
        # In a full implementation, this would save plots to files
        # and generate the appropriate LaTeX includegraphics commands
        return "% Plot generation would appear here\n"

    def _compile_latex(self, tex_path: Path):
        """Compile LaTeX document to PDF"""
        try:
            import latex
            latex.compile(tex_path)
        except ImportError:
            self.logger.warning("LaTeX compilation tools not available")

    def _generate_markdown(self, results: Dict) -> str:
        """Generate markdown report"""
        template = self._load_template('markdown')

        data = {
            'title': "RHVT+ Riemann Hypothesis Verification Report",
            'date': datetime.now().isoformat(),
            'metadata': self._format_metadata(results),
            'results': self._format_markdown_results(results)
        }

        return template.format(**data)

    def _generate_json(self, results: Dict) -> str:
        """Generate JSON report"""
        return json.dumps(results, indent=2)

    def _generate_text(self, results: Dict) -> str:
        """Generate plain text report"""
        template = self._load_template('text')

        data = {
            'title': "RHVT+ Riemann Hypothesis Verification Report",
            'date': datetime.now().isoformat(),
            'metadata': self._format_metadata(results),
            'results': self._format_text_results(results)
        }

        return template.format(**data)

    def _load_template(self, format: str) -> str:
        """Load template for report format"""
        template_file = self.template_dir / f"report.{format}.tpl"

        if template_file.exists():
            return template_file.read_text()

        # Fallback to built-in templates
        builtin_templates = {
            'latex': r"""
        \documentclass{{article}}
        \usepackage{{amsmath, amssymb, graphicx, hyperref}}
        \title{{{title}}}
        \date{{{date}}}

        \begin{{document}}
        \maketitle

        \section{{Metadata}}
        \begin{{itemize}}
        {metadata}
        \end{{itemize}}

        \section{{Results}}
        {results}

        {plots}

        \end{{document}}
        """,
                    'markdown': """
        # {title}

        **Date**: {date}

        ## Metadata
        {metadata}

        ## Results
        {results}
        """,
                    'text': """
        {title}
        {underline}

        Date: {date}

        METADATA:
        {metadata}

        RESULTS:
        {results}
        """
        }

        return builtin_templates.get(format, "")

    def _format_metadata(self, results: Dict) -> str:
        """Format metadata section based on report type"""
        format = self.config.get('reporting', 'format', default='latex')

        meta = [
            f"Zeros computed: {len(results['zeros'])}",
            f"Precision: {self.config.get('precision', 'digits')} digits",
            f"Computation backend: {results['backend']}"
        ]

        if format == 'latex':
            return "\n".join(f"\\item {item}" for item in meta)
        elif format == 'markdown':
            return "\n".join(f"- {item}" for item in meta)
        else:
            return "\n".join(f"  â€¢ {item}" for item in meta)

    def _format_latex_results(self, results: Dict) -> str:
        """Format results section for LaTeX"""
        sections = []

        # Critical line verification
        if 'critical_line' in results:
            cl = results['critical_line']
            sections.append(r"""
\subsection{Critical Line Verification}
\begin{itemize}
\item Maximum deviation: ${max_dev:.2e}$
\item Mean deviation: ${mean_dev:.2e}$
\item Status: \textbf{${status}$}
\end{itemize}
""".format(
                max_dev=cl['max_deviation'],
                mean_dev=cl['mean_deviation'],
                status="PASS" if cl['within_tolerance'] else "FAIL"
            ))

        # Functional equation verification
        if 'functional_equation' in results:
            fe = results['functional_equation']
            sections.append(r"""
\subsection{Functional Equation Verification}
\begin{itemize}
\item Maximum error: ${max_err:.2e}$
\item Mean error: ${mean_err:.2e}$
\item Status: \textbf{${status}$}
\end{itemize}
""".format(
                max_err=fe['max_error'],
                mean_err=fe['mean_error'],
                status="PASS" if fe['within_tolerance'] else "FAIL"
            ))

        return "\n".join(sections)

    def _format_markdown_results(self, results: Dict) -> str:
        """Format results section for markdown"""
        sections = []

        if 'critical_line' in results:
            cl = results['critical_line']
            sections.append("""
### Critical Line Verification
- Maximum deviation: {max_dev:.2e}
- Mean deviation: {mean_dev:.2e}
- Status: **{status}**
""".format(
                max_dev=cl['max_deviation'],
                mean_dev=cl['mean_deviation'],
                status="PASS" if cl['within_tolerance'] else "FAIL"
            ))

        if 'functional_equation' in results:
            fe = results['functional_equation']
            sections.append("""
### Functional Equation Verification
- Maximum error: {max_err:.2e}
- Mean error: {mean_err:.2e}
- Status: **{status}**
""".format(
                max_err=fe['max_error'],
                mean_err=fe['mean_error'],
                status="PASS" if fe['within_tolerance'] else "FAIL"
            ))

        return "\n".join(sections)

    def _format_text_results(self, results: Dict) -> str:
        """Format results section for plain text"""
        sections = []

        if 'critical_line' in results:
            cl = results['critical_line']
            sections.append("""
CRITICAL LINE VERIFICATION:
  Max deviation: {max_dev:.2e}
  Mean deviation: {mean_dev:.2e}
  Status: {status}
""".format(
                max_dev=cl['max_deviation'],
                mean_dev=cl['mean_deviation'],
                status="PASS" if cl['within_tolerance'] else "FAIL"
            ))

        if 'functional_equation' in results:
            fe = results['functional_equation']
            sections.append("""
FUNCTIONAL EQUATION VERIFICATION:
  Max error: {max_err:.2e}
  Mean error: {mean_err:.2e}
  Status: {status}
""".format(
                max_err=fe['max_error'],
                mean_err=fe['mean_error'],
                status="PASS" if fe['within_tolerance'] else "FAIL"
            ))

        return "\n".join(sections)

# ======================
# MAIN APPLICATION
# ======================
class RHVTApplication:
    """Main application class for RHVT+"""

    def __init__(self, config: ConfigManager):
        self.config = config
        self.logger = logging.getLogger("RHVT")
        self._setup_logging()
        self.backend = self._init_backend()
        self.symbolic_engine = self._init_symbolic_engine() if config.get('verification', 'symbolic', 'enabled') else None
        self.report_generator = ReportGenerator(config)
        self.results = {
            'config': config.config,
            'provenance': config.provenance,
            'timestamp': datetime.now().isoformat()
        }

    def _setup_logging(self):
        """Configure logging system"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('rhvt.log'),
                logging.StreamHandler()
            ]
        )

    def _init_backend(self) -> ComputationBackend:
        """Initialize computation backend"""
        backend_type = self.config.get('computation', 'backend', default='auto')

        if backend_type == 'auto':
            # Auto-select based on system capabilities and problem size
            num_zeros = self.config.get('computation', 'num_zeros', default=10)

            if num_zeros > 1000 and BackendManager.available_backends():
                backend_type = 'gpu'
            elif num_zeros > 10000 and ('cluster' in BackendManager.available_backends()):
                backend_type = 'cluster'
            else:
                backend_type = 'cpu'

        return BackendManager.get_backend(backend_type, self.config)

    def _init_symbolic_engine(self) -> SymbolicEngine:
        """Initialize symbolic computation engine"""
        try:
            return SymbolicEngine(self.config)
        except Exception as e:
            self.logger.warning(f"Failed to initialize symbolic engine: {str(e)}")
            return None

    def run(self):
        """Execute the full analysis pipeline"""
        self.logger.info("Starting RHVT+ analysis")

        try:
            # Load plugins
            self.config.load_plugins()

            # Compute zeros
            zeros = self._compute_zeros()
            self.results['zeros'] = zeros
            self.results['backend'] = self.backend.__class__.__name__

            # Critical line verification
            if self.config.get('verification', 'critical_line', 'enabled', default=True):
                self._verify_critical_line(zeros)

            # Functional equation verification
            if self.config.get('verification', 'functional_equation', 'enabled', default=True):
                self._verify_functional_equation(zeros)

            # Symbolic verification
            if self.symbolic_engine:
                self._perform_symbolic_verification()

            # Spacing analysis
            if self.config.get('analysis', 'spacings', 'enabled', default=True) and len(zeros) >= 3:
                self._analyze_spacings(zeros)

            # Generate visualizations
            self._generate_visualizations()

            # Generate final report
            report_path = self._generate_report()

            self.logger.info(f"Analysis complete. Report saved to {report_path}")
            return 0

        except Exception as e:
            self.logger.error(f"Analysis failed: {str(e)}", exc_info=True)
            return 1
        finally:
            self.backend.cleanup()

    def _compute_zeros(self) -> List[complex]:
        """Compute zeta zeros using configured backend"""
        num_zeros = self.config.get('computation', 'num_zeros', default=10)
        self.logger.info(f"Computing first {num_zeros} non-trivial zeros")

        start_time = time()
        zeros = self.backend.compute_zeros(num_zeros)
        elapsed = time() - start_time

        self.results['computation'] = {
            'time': elapsed,
            'zeros_per_second': len(zeros) / elapsed if elapsed > 0 else float('inf'),
            'zeros_computed': len(zeros)
        }

        self.logger.info(
            f"Computed {len(zeros)} zeros in {elapsed:.2f}s "
            f"({elapsed/len(zeros):.3f}s per zero)"
        )

        return zeros

    def _verify_critical_line(self, zeros: List[complex]):
        """Verify zeros lie on critical line"""
        self.logger.info("Verifying critical line")

        result = self.backend.verify_critical_line(zeros)
        self.results['critical_line'] = result

        if result['within_tolerance']:
            self.logger.info(
                f"All zeros on critical line (max deviation: {result['max_deviation']:.2e})"
            )
        else:
            self.logger.warning(
                f"Critical line deviations found (max: {result['max_deviation']:.2e}, "
                f"{len(result['outliers'])} outliers)"
            )

    def _verify_functional_equation(self, zeros: List[complex]):
        """Verify functional equation"""
        test_points = self.config.get('verification', 'functional_equation', 'test_points', default=10)

        if isinstance(test_points, int):
            # Select test points from computed zeros
            step = max(1, len(zeros) // test_points)
            test_points = [z.imag for z in zeros[::step][:test_points]]

        self.logger.info(f"Verifying functional equation at {len(test_points)} points")

        result = self.backend.verify_functional_equation(test_points)
        self.results['functional_equation'] = result

        if result['within_tolerance']:
            self.logger.info(
                f"Functional equation verified (max error: {result['max_error']:.2e})"
            )
        else:
            self.logger.warning(
                f"Functional equation errors found (max: {result['max_error']:.2e})"
            )

    def _perform_symbolic_verification(self):
        """Perform symbolic verification of functional equation"""
        self.logger.info("Performing symbolic verification")

        timeout = self.config.get('verification', 'symbolic', 'timeout', default=30)
        result = self.symbolic_engine.verify_functional_equation(timeout)
        self.results['symbolic_verification'] = result

        if result.get('verified', False):
            self.logger.info(
                f"Symbolic verification passed (error: {result.get('error', 0):.2e})"
            )
        else:
            self.logger.warning(
                f"Symbolic verification failed (error: {result.get('error', 'unknown')})"
            )

    def _analyze_spacings(self, zeros: List[complex]):
        """Analyze spacing distribution between zeros"""
        self.logger.info("Analyzing zero spacings")

        analysis_method = AnalysisManager.get_method('spacings')
        result = analysis_method(zeros, self.config)
        self.results['spacing_analysis'] = result

        if 'gue_comparison' in result:
            self.logger.info(
                f"Spacing analysis complete. GUE conformity: {result['gue_comparison']['conforms']} "
                f"(p-value: {result['gue_comparison']['p_value']:.4f})"
            )
        else:
            self.logger.info("Spacing analysis complete")

    def _generate_visualizations(self):
        """Generate visualizations based on configuration"""
        viz_mode = self.config.get('visualization', 'mode', default='interactive')

        if viz_mode == 'dashboard':
            viz_method = VisualizationManager.get_method('dashboard')
        elif viz_mode == 'interactive':
            viz_method = VisualizationManager.get_method('interactive')
        else:
            viz_method = VisualizationManager.get_method('static')

        # Generate visualizations
        viz_method(
            self.results['zeros'],
            self.results.get('spacing_analysis', {}),
            self.config
        )

    def _generate_report(self) -> Path:
        """Generate and save final report"""
        report_format = self.config.get('reporting', 'format', default='latex')
        self.logger.info(f"Generating {report_format.upper()} report")

        return self.report_generator.save(self.results)

# ======================
# COMMAND LINE INTERFACE
# ======================
def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description="RHVT+ - Advanced Riemann Hypothesis Verification Toolkit",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # Computation parameters
    parser.add_argument("-n", "--num-zeros", type=int,
                      help="Number of zeros to compute")
    parser.add_argument("-p", "--precision", type=int,
                      help="Decimal digits of precision")
    parser.add_argument("--computation-mode", choices=['auto', 'cpu', 'gpu', 'cluster'],
                      help="Computation backend to use")
    parser.add_argument("--no-cache", action='store_true',
                      help="Disable result caching")
    parser.add_argument("--workers", type=int,
                      help="Number of parallel workers")

    # Verification options
    parser.add_argument("--no-critical-line", action='store_true',
                      help="Skip critical line verification")
    parser.add_argument("--no-functional-eq", action='store_true',
                      help="Skip functional equation verification")
    parser.add_argument("--symbolic-verify", action='store_true',
                      help="Enable symbolic verification")

    # Analysis options
    parser.add_argument("--no-spacings", action='store_true',
                      help="Skip spacing analysis")
    parser.add_argument("--analyze-correlations", action='store_true',
                      help="Enable correlation analysis")
    parser.add_argument("--anomaly-detection", action='store_true',
                      help="Enable anomaly detection")

    # Visualization options
    parser.add_argument("--plot-type", choices=['static', 'interactive', 'dashboard'],
                      help="Type of visualization to generate")
    parser.add_argument("--dashboard", action='store_true',
                      help="Launch interactive web dashboard")
    parser.add_argument("--dashboard-port", type=int,
                      help="Port for web dashboard")

    # Reporting options
    parser.add_argument("--output-format", choices=['text', 'json', 'markdown', 'latex'],
                      help="Format for results reporting")
    parser.add_argument("--no-provenance", action='store_true',
                      help="Disable provenance tracking")

    # Configuration file
    parser.add_argument("--config", type=str,
                      help="Path to YAML config file")

    return parser.parse_args()

def main():
    """Main entry point for command line execution"""
    print("\nRHVT+ - Advanced Riemann Hypothesis Verification Toolkit")
    print("=" * 60)

    # Parse command line arguments
    args = parse_args()

    # Initialize configuration
    config = ConfigManager(args.config if args.config else None)
    config.update_from_cli(args)

    # Create and run application
    app = RHVTApplication(config)
    return app.run()

if __name__ == "__main__":
    sys.exit(main())
